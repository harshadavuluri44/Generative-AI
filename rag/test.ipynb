{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d05e64e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Reading harsha-s resume for shortlisting' metadata={'source': 'Desktop', 'author': 'Harsha Davuluri', 'date': '17-02-2026', 'no_of_pages': '1'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "doc = Document(\n",
        "    page_content=\"Reading harsha-s resume for shortlisting\",\n",
        "    metadata={\n",
        "        \"source\":\"Desktop\",\n",
        "        \"author\":\"Harsha Davuluri\",\n",
        "        \"date\":\"17-02-2026\",\n",
        "        \"no_of_pages\":\"1\"\n",
        "    }\n",
        ")\n",
        "print(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "effa9c46",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={'producer': '3.0.30 (5.1.14)', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-11-01T19:20:54+05:30', 'author': 'Ajay Babu P', 'moddate': '2025-12-19T18:39:51+01:00', 'source': '../Harsha_Resume_9390003039.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Mano Harsha Davuluri \\n                    EMAIL ID: manoharsha44@gmail.com \\n                     MOBILE: \\n       LINKEDIN URL: https://www.linkedin.com/in/mano-harsha-davuluri/ \\n \\n• SUMMARY \\npipelines. Specializes in cloud -native data lakes, dimensional  data modeling, and Batch processing using Spark, AWS, \\nML Models and Databricks. Proven expertise in leading cross- functional teams and translating complex business \\nrequirements into scalable data solutions. Demonstrated success in optimizing performance, implementing data \\ngovernance and data driven innovation across enterprise environments. \\n \\nTechnical Skills \\n• Cloud & Platforms: AWS (S3, Glue, EMR, Lambda, Redshift, DynamoDB, EC2), Databricks, Apache spark. \\n• Data Warehousing & Storage: Amazon Redshift, SQL, DynamoDB, Delta Tables, Data Lakehouse, Data Lakes, Parquet. \\n• Programming \\n• Big Data & ETL Tools: Spark, Delta Lake, Airflow, Hadoop. \\n• Data Modeling & Architecture: Dimensional Modeling, Star/Snowflake Schema, Data Governance, Cloud Security. \\n• Development & Collaboration Tools: Jira, Git, Bitbucket, Docker, CI/CD pipelines, Jenkins, Agile methodologies. \\n \\nCertification \\n \\n• Databricks Certified Data Engineer Associate \\n \\nEXPERIENCE SUMMARY \\n \\nData Engineer II, Epsilon \\nBangalore, India | March 2025 – Current \\n• Designed and implemented comprehensive Data Quality framework for Prospect project, incorporating automated \\ndiscrepancy detection and real time alerting mechanisms to ensure data integrity and compliance. \\n• Constructed scalable ETL/ELT data solutions processing over 150+ billions record daily into data lakes and warehouses \\nusing spark, developed ML Models enhancing decision-making and resulting in 25% boost in quarterly revenue. \\n• Optimized and tuned Spark jobs for large-scale datasets (30+ TB), implementing performance best practices and \\nreducing infrastructure costs by 46%. \\n• Collaborated with cross-functional teams to establish data governance standards and implement CI/CD pipelines for \\nautomated data processing workflows. \\n \\nData Engineer I, Epsilon \\nBangalore, India | August 2023 – March 2025 \\n• Built end-to-end data pipelines encompassing Ingestion, extract-transform-load processes, data archiving, warehousing \\nand reporting automation using Apache Spark on Databricks Delta tables. \\n• Collaborated with solution architects and business stakeholders to design and implement complex ML models for \\npredictive analytics and BI solutions. \\n• Leveraged comprehensive AWS ecosystem including EMR, Glue, Lambda, S3, Redshift and DynamoDB for efficient \\ndata processing and storage based on client requirements. \\n \\nEDUCATION QUALIFICATION \\n• Bachelor of Technology – Electrical and Electronics Engineering \\nNIT Surathkal, Karnataka, India | 7.32 CGPA \\n: Python, SQL, PySpark, DBT,  Shell Scripting, JSON, YAML.\\n: Data Engineer with 2.5+ years of experience building large-scale, resilient data platforms and ETL/ELT\\n9390003039')]\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# current working file is in rag folder, so move one directory back by using (..)\n",
        "loader = PyPDFLoader('../Harsha_Resume_9390003039.pdf')\n",
        "doc = loader.load()\n",
        "print(doc)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
